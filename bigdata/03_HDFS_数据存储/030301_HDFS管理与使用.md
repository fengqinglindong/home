## 权限管理
### UGO权限变更
	HDFS权限分为属主、用户组、其他等角色。
	格式：
		Hadoop fs -chmod <PERM> <PATH>
		
		hadoop fs -chown <user:group> <path>

		ex:
			1.变更目录或文件的权限
				hadoop fs -chmod 750 /user/portal/foo
				
			2.变更目录或文件的属主或用户组
				hadoop fs -chown :portal /user/portal/foo
				
			3.变更用户组
				hadoop fs -chgrp portal_group1 /user/portal/foo

	注意：HDFS没有UID和GID，却有粘置位，通过粘置位来简化用户的权限管理，可以让特定用户共享特定目录的读写权限
	，但只要特定子目录的属主才有删除权限。使用相关的chmod、chown必须是超级用户或是文件或目录的属主同时是
	该用户组的成员才能操作这些命令。目录的权限组变更后，需要手动刷新用户组才能让变更生效，因为HDFS的缓存不会让变更立即生效。

### ACL权限变更
- 为了解决HDFS细腻度权限控制，HDFS提供了类似POSIX ACL特性

- 一条ACL规则由若干个ACL条目组成，每个条目确定一个用户或用户组的权限位。ACL条目由类型名、可选名称、权限字符串组成，以：为分隔符。

- 格式：hadoop fs [generic options] -setfacl [-R][{-b|-k}{-m|-x<acl_spec>}<path>]|[--set <acl_spec><path>]

- ex:

	user::rw-

	user:bruce:rwx
	
	group::r-x

	group:sales:rwx

	mask::r--

	other::r--
	
注意：若不指定可选名称，表示对此用户的目录或文件生效。特定用户bruce经过mask过滤权限为：r--,同理group中的sales权限为：r--

- 当目录或文件设置ACL规则后，权限位后会有个 + 号如下：

	drwxr-xr-x+ -da hdfs

### ACL的相关操作

1. 为目录添加访问权限
	
	hadoop fs -setfacl -m user:abc:r-x /user/hadoop

2. 为目录添加可继承权限

	hadoop fs -setfacl -m default:user:abc:r-x,default:group:xxx:r-x,default:other::r-x /user/hadoop

3. 删除目录权限

	hadoop fs -setfacl -b /user/hadoop

4. 删除特定权限，保留其他权限

	hadoop fs -setfacl -x user:abc:rwx /user/hadoop

注意：ACL会占用NameNode的内存，尽量少使用。

### 权限管理总结

1. 为不同的文件目录设置属主和权限位，将数据通过不同的用户权限隔离开来。
2. 用户间共享的数据，优先使用用户组权限实现。
3. 因为设置共享目录的权限，需要递归的将该共享目录的上级或父目录添加只读ACL。
4. 对于特定的目录，用户组中的用户可能有些事r--,有些事rw-
5. 如果上述权限需要在子目录中继承下去，则需要设定用户权限的default规则（尽量少用）。
6. 用户组名与目录名绑定。

### 配额管理
	文件数/大小配额
	1. 获取一个目录的配额设置
		
		hadoop fs -count [-q]<dirname>

	2. 设置目录的配额

		hdfs dfsadmin -setQuota <quota><dirname>
		
		hdfs dfsadmin -setSpaceQuota <quota><dirname>

	注意：HDFS不适合存储大量的小文件。小文件会占用NameNode的内存，进入导致相应的请求操作过度负担。

### 数据均衡
	解决HDFS数据不均衡的问题，特别是加入服务器后。

	使用工具：
		$HADOOP_HOME/sbin/start-balaner.sh
			[-policy <policy>]  the balancing policy:datanode or blockpool
			[-threshold <threshold>]
			[-exclude [-f <hosts-file>|<comma-separated list of hosts>]]
			[-include [-f <hosts-file>|<comma-separated list of hosts>]]
			[-idleiterations <idleiterations>]

### 升级和回滚
	1. 准备滚动升级

		执行 hdfs dfsadmin -rollingUpgrade prepare 来生成备份的fsimage
		执行hdfs dfaadmin -rollingUpgrade query 查看是否完成备份。

	2. 升级ANN和SNN

		关闭NN2（SNN），使用-rollingUpgrade 选项重启NN2，此时NN2还是SNN，需要手动触发切换，将NN2（SNN）切换到ANN
		关闭NN1，并升级NN1的软件包；再通过-rollingUpgrade started启动NN1,这时NN1位SNN。

	3. 升级DN

		选择个别DN节点，执行hdfs dfsadmin -shutdownDatanode <DATANODE_HOST:IPC_PORT> upgrade ，（此时为生成一个rollingbock文件）关闭一个DN；升级并重启该DN。重复操作，完成所有DN升级重启。

	4. 结束升级
	
		执行hdfs dfsadmin -rollingUpgrade finalize 命令来结束这次滚动升级。

	回滚：（需要停服）
		
		- 关闭所有的NN和DN
		- 恢复所有服务器上的版本到升级之前的状态
		- 通过-rollingUpgrade rollback启动ANN
		- 通过 -bootstrapStandby正常启动SNN
		- 通过-rollback启动所有的DN

### 此外常用的HDFS管理命令
	
	dfsadmin -safemode [enter|leave|get]

	dfsadmin -refreshNodes

	dfsadmin -reconfig <datanode:port> <start|status>

	- 日常Fs shell 命令
		
		通过Hadoop fs 查看帮助说明

