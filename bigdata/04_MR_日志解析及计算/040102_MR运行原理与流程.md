## Map的运行过程

![](https://i.imgur.com/lQtaeVh.png)

### 过程图解释
	
- Map的输入数据源可以多种多样，这里使用HDFS的文件为输入数据源，文件在HDFS上是以块为单位存储的，将block划分为一个个的数据分片（split），每一个split由一个或多个block组成。
- MapReduce将数据以K/V的形式读取出来，并且将这些数据交给自定义的Map函数进行处理。
- 处理完数据后，以K/V写出来，交给MapReduce的计算框架。
- MapReduce的计算框架会对数据进行划分（partition），同一个partition会分到同一个Reduce节点上，进行处理。
- Map如何使用将数据进行划分，默认使用hash算法，对key值进行hash，这样既能保证相同key值的数据划分到同一个partition中，又能保证不同的partition的数据时大致相当的。
	
### Map的知识点

- Block时HDFS上的文件的存储单元，split时逻辑划分，split不包含数据，只包含这些数据的位置信息。
- HDFS上的文件特点：
	
	1. 一个split包含一个或多个block，默认是一对一
	2. 一个split不会包含两个File的block，不会跨越File边界。
- 一个Map只会处理一个Split
- Map处理完的数据又会分为不同的partition，一类partition对应一个Reduce。一个程序中的Map与Reduce数量是由Split和partition的数量决定的。


## Reduce的运行过程

![](https://i.imgur.com/8OPMXOj.png)

### 过程图解释

- Map处理完后，Reduce节点会在各个Map上将属于自己的数据copy到自己的内存缓冲区中。
- 将各自的数据合并成一个大的数据集，并且按照key值进行聚合，把聚合后的value值作为一个迭代器交给用户使用
- 这些数据经过用户自定义的Reduce函数进行处理后，同样会以K/V的形式输出，默认输出到HDFS上的文件。


## Shuffle过程

没有排序的MapReduce是没有灵魂的。

什么时候进行排序？

在Map 和 Reduce 中间发生的。这个过程就叫Shuffle过程


![](https://i.imgur.com/o9X0J1V.png)

### 过程图解释



#### Map阶段的Shuffle过程

- 数据通过用户自定义的map函数处理后，会放进一个叫环形缓冲区的地方。环形缓冲区在内存中，分为数据区和索引区。数据区存放真实数据的，索引区存放这些数据对应的key值、partition以及位置信息的。
- 当环形缓冲区中的数据达到一定量时，会将数据溢写到一个文件中（spill过程）。在溢写之前会将数据进行排序，首先将索引区的数据按照key和partition进行排序。
- 排完序后，按照顺序将数据区的数据一个个写入文件中。保证溢写的小文件中，我们的数据是按照partition之类，按照key值进行排序的。
- 将溢写出来的文件合并成一个大文件。并且保证每个partition中是按照key值有序的。将两个有序的数据集进行排序是比较简单的。

#### Reduce阶段的Shuffle过程

- Reduce节点会将属于自己的数据copy到自动缓冲区buffer中，当buffer中的数据达到一定比例的时候，同样发生溢写，保证每个溢写出来的小文件保持有序。
- 后台启一个进程，将小文件合成一个大文件。一轮轮的合并，将大文件合并成一个数据集，数据集中的数据是有序的。相同的key值所对应的value值是挨在一块的。
- 最后将这些数据交给Reduce程序进行聚合。

### Shuffle过程的知识点

- Map端：

	1. Collect阶段，将数据放进环形缓冲区，缓冲区分为数据区和索引区。
	2. Sort阶段，对同在一个partition内的索引按照key排序。
	3. Spill阶段，根据排好序的索引将数据按照顺序写到文件中。
	4. Merge阶段，将Spill生成的小文件分批合并排序成一个大文件。

- Reduce端：
	
	1. copy阶段，将Map端的数据分批copy到Reduce的缓冲区。
	2. Spill阶段，将内存缓冲区的数据按顺序写到文件中。
	3. Merge阶段，将溢写文件合并成一个排序的数据集。


## Combine优化

MapReduce程序最终是按照Key值进行聚合，对于value值进行计算的。提前将聚合好的value值进行计算，这个过程叫做Combine过程。

- Map端：

	1. 在数据排好序后，溢写到磁盘前，相同key值的value值是在一块的，对这些value值进行计算，比如说累加操作，我们这个时候可以进行一次Combiner运算。
	2. 在溢写出来的小文件合并之前也可以进行一次Combiner，但是MapReduce规定至少存在三个溢出文件，才进行Combiner运算。可以通过min.num.spills.for.combine设置阈值。

- Reduce端：

	1. 在合并溢出文件输出到磁盘之前，运行Combiner。（并不是任何阶段都可以设置Combiner，这样会导致REduce阶段的程序的输出结果造成很大的影响）
	

## MR的运行过程


![](https://i.imgur.com/3yK32zm.png)

### 过程图解释说明

1. 一个File会被分成多个数据片，每一个Split会对应一个map，map处理完会放到环形缓冲区中。
2. 这些数据会被溢写到一个个的小文件中，然后把小文件合成一个大文件，大文件会按照partition内部进行排序。
3. Reduce节点会将属于自己的数据copy到Reduce节点中的缓冲区中，并且把这些数据进行合并。交给Reduce节点进行处理，处理后的结果输出到HDFS上。

## MapReduce on Yarn
	
MapReduce程序如何运行在集群上的。


![](https://i.imgur.com/SiwyqM1.png)

### 资源调度工具Yarn，结构图说明

- Resource Manager 负责调度管理整个集群上的资源。
- 每一个计算节点上都有一个Node Manager，来负责该节点上的计算资源，把计算资源抽象成Container。每一个Container包含一定的CPU核数和一定大小的内存。
- 一个应用程序，由一个App Master来负责管理。APP Master负责将应用程序运行在各个节点的Container上。

### Yarn组件

* ResourceManager：主要职责是调度，对应用程序的整体进行资源分配。
* Container：单个节点上的物理资源的集合，比如内存和CPU。
* NodeManege：管理Container生命周期，资源使用情况，节点健康状况。
* ApplicationMaster：协调集群中的应用程序，与ResourceManager协商资源。

![](https://i.imgur.com/D1A5PQA.png)

### MapReduce on Yarn上的过程图说明

1. MapReduce程序会在客户端启动，客户端回想ResourceManager发送App请求，ResourceManager会返回一个App ID给客户端。
2. 然后客户端会根据APPID，用户名，队列，令牌向ResourceManager进行请求。同时，客户端会将程序所用到的jar包，资源文件以及程序运行时所用到的数据传送到HDFS上。
3. ResourceManager会分配一个container 0的资源包，由NM启动AppMaster。并且RM将集群的容量信息发送到MRAppMaster。由AppMaster计算此程序所用到的资源量。然后，向ResourceManager请求分配更多的container。
4. 由NodeManager在各个节点上面，把Map任务和Reduce任务启动起来。

### 上述过程总结

1. 客户端提交MR程序，向RM请求资源，并将程序依赖的资源上传到HDFS。
2. RM分配一个Container 0 ，NM启动AM，用来管理这个MR程序，AM计算好所需资源后向RM请求资源。
3. NM在各个节点上启动MapTask和ReduceTask。
