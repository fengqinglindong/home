## 数据划分-导入 ##

Sqoop是如何在mapreduce中尽量均衡切分数据的。

现有一个Order表，需要将其数据导入到HDFS上，主键是id。如下图所示：

![](https://i.imgur.com/t3cUwGT.png)

Sqoop解析完命令参数后，查找参数指定的分片字段的数据范围，假设分片字段为Id，通过JDBC接口找到ID的最大值和最小值，数据范围除以map数等到每个map传输数据的ID范围。  
每个Map使用SQL语句进行数据筛选，即在SQL中添加where条件，比如map1 的ID<1000 and Id>1.每个Map多会在HDFS上生成一个文件，存储导入的数据。

## 数据划分-导出 ##

数据导出跟导入正好相反，是把HDFS上的文件导出到数据库中，如下图：
![](https://i.imgur.com/uL14IZV.png)

导出任务的数据划分完全依赖于HDFS的InputFormat的split划分，默认使用CombineInputFormat，尽量把同一个节点的数据使用同一个map来处理，这样可以减少众多小文件导致的创建map任务的开销，提高任务执行效率。
  
但是，如果导出的数据文件是压缩格式且压缩格式不能分片，那么就要按照单个文件分片，每一个文件生成一个map进行导出。
导出任务的分片逻辑较复杂，用户指定的并发参数往往不会生效。

## 总结 ##

Sqoop是基于MapReduce框架的数据同步工具，启用多个map进行数据的并发导入和导出。对于导入任务，数据的分片是基于数据中数据的范围和用户指定的并发数；对于导出任务，数据分片是依赖HDFS的 FileInputFormat 的分片策略。